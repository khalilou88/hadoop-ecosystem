services:
  namenode:
    image: apache/hadoop:3.3.6
    hostname: namenode
    container_name: namenode
    ports:
      - "9870:9870" # HDFS Web UI
      - "9000:9000" # HDFS default port
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_namenode_http_address=0.0.0.0:9870
      - HDFS_CONF_dfs_replication=1
      - ENSURE_NAMENODE_DIR=/tmp/hadoop-root/dfs/name
    volumes:
      - namenode_data:/tmp/hadoop-root/dfs/name
    env_file:
      - ./hadoop.env
    command: ["hdfs", "namenode"]
    healthcheck:
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - hadoop-net

  datanode:
    image: apache/hadoop:3.3.6
    hostname: datanode
    container_name: datanode
    depends_on:
      namenode:
        condition: service_healthy
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_datanode_http_address=0.0.0.0:9864
      - ENSURE_DATANODE_DIR=/tmp/hadoop-root/dfs/data
    volumes:
      - datanode_data:/tmp/hadoop-root/dfs/data
    env_file:
      - ./hadoop.env
    command: ["hdfs", "datanode"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9864"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - hadoop-net

  resourcemanager:
    image: apache/hadoop:3.3.6
    hostname: resourcemanager
    container_name: resourcemanager
    depends_on:
      namenode:
        condition: service_healthy
    ports:
      - "8088:8088" # YARN Web UI
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_nodemanager_aux_services=mapreduce_shuffle
      - YARN_CONF_yarn_log_aggregation_enable=true
      - MAPRED_CONF_mapreduce_framework_name=yarn
    env_file:
      - ./hadoop.env
    command: ["yarn", "resourcemanager"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://resourcemanager:8088/ws/v1/cluster/info"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - hadoop-net

  nodemanager:
    image: apache/hadoop:3.3.6
    hostname: nodemanager
    container_name: nodemanager
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_nodemanager_aux_services=mapreduce_shuffle
      - YARN_CONF_yarn_log_aggregation_enable=true
      - MAPRED_CONF_mapreduce_framework_name=yarn
    env_file:
      - ./hadoop.env
    command: ["yarn", "nodemanager"]
    healthcheck:
      test: ["CMD", "yarn", "node", "-list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - hadoop-net

  historyserver:
    image: apache/hadoop:3.3.6
    hostname: historyserver
    container_name: historyserver
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
    ports:
      - "8188:8188" # MapReduce JobHistory Web UI
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - MAPRED_CONF_mapreduce_jobhistory_address=historyserver:10020
      - MAPRED_CONF_mapreduce_jobhistory_webapp_address=0.0.0.0:8188
    volumes:
      - hadoop_history:/tmp/hadoop-yarn/staging/history
    env_file:
      - ./hadoop.env
    command: ["mapred", "historyserver"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://historyserver:8188"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - hadoop-net

volumes:
  namenode_data:
  datanode_data:
  hadoop_history:

networks:
  hadoop-net:
    driver: bridge